{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers.replay_buffer import ReplayBuffer\n",
    "from helpers.chain_environment import SimpleChain\n",
    "from helpers.shedules import LinearSchedule\n",
    "from helpers.create_empty_directory import create_empty_directory\n",
    "from helpers.plots import plot_q_func_and_visitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dqn import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_range = np.arange(5, 30, 5).astype('int32')\n",
    "seed_range =[10, 42, 51, 38, 50]  #np.array([10, 42, 51, 38, 50])\n",
    "eps_params = {'exploration_fraction': 0.25,\n",
    "              'exploration_final_eps': 0.001}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_params = dict( gamma=0.99, write_logs=None, do_pretraining=True,\n",
    "                     plot_freq=None, target_type='double_q_learning')\n",
    "\n",
    "experiments = []\n",
    "\n",
    "experiments.append({'name': 'eps_greedy',\n",
    "                    'params': dict(eps_params=eps_params, act_type='epsilon_greedy', reward_shaping_type=None),\n",
    "                    'iterate_seeds': True})\n",
    "# ----------------------------------------------------------------------------- #\n",
    "experiments.append({'name': 'ucb-1',\n",
    "                    'params': dict(eps_params=None, act_type='ucb-1', reward_shaping_type=None),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "\n",
    "experiments.append({'name': 'ucb-2',\n",
    "                    'params': dict(eps_params=None, act_type='ucb-2', reward_shaping_type=None),\n",
    "                    'iterate_seeds': True})\n",
    "# ----------------------------------------------------------------------------- #\n",
    "experiments.append({'name': 'count_based_state_action',\n",
    "                    'params': dict(eps_params=None, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_state_action'),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "experiments.append({'name': 'count_based_next_state_action',\n",
    "                    'params': dict(eps_params=None, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_next_state_action'),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "experiments.append({'name': 'count_based_state',\n",
    "                    'params': dict(eps_params=None, act_type='epsilon_greedy',\n",
    "                                       reward_shaping_type='count_based_state'),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "experiments.append({'name': 'count_based_next_state',\n",
    "                    'params': dict(eps_params=None, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_next_state'),\n",
    "                    'iterate_seeds': True})\n",
    "# ----------------------------------------------------------------------------- #\n",
    "experiments.append({'name': 'eps_greedy_count_based_state_action',\n",
    "                    'params': dict(eps_params=eps_params, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_state_action'),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "experiments.append({'name': 'eps_greedy_count_based_next_state_action',\n",
    "                    'params': dict(eps_params=eps_params, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_next_state_action'),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "experiments.append({'name': 'eps_greedy_count_based_state',\n",
    "                    'params': dict(eps_params=eps_params, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_state'),\n",
    "                    'iterate_seeds': True})\n",
    "\n",
    "experiments.append({'name': 'eps_greedy_count_based_next_state',\n",
    "                    'params': dict(eps_params=eps_params, act_type='epsilon_greedy',\n",
    "                                   reward_shaping_type='count_based_next_state'),\n",
    "                    'iterate_seeds': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim=10\n",
    "chain_env=SimpleChain(input_dim)\n",
    "num_actions = chain_env.action_space.n\n",
    "dim_states = chain_env.observation_space.shape[0]\n",
    "\n",
    "eps_params = {'exploration_fraction': 0.5,\n",
    "              'exploration_final_eps': 0.05}\n",
    "\n",
    "tau_params = {'fraction': 0.95,\n",
    "              'final_tau': 0.05}\n",
    "\n",
    "alpha_params = {'fraction': 0.95,\n",
    "                'initial_alpha': 10,\n",
    "                'final_alpha': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_greedy\n",
      "ucb-1\n",
      "ucb-2\n",
      "count_based_state_action\n",
      "count_based_next_state_action\n",
      "count_based_state\n",
      "count_based_next_state\n",
      "eps_greedy_count_based_state_action\n",
      "eps_greedy_count_based_next_state_action\n",
      "eps_greedy_count_based_state\n",
      "eps_greedy_count_based_next_state\n",
      "CPU times: user 21h 27min 4s, sys: 4min 47s, total: 21h 31min 51s\n",
      "Wall time: 7h 26min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "folder = 'results/dqn/chain/'\n",
    "create_empty_directory(folder)\n",
    "\n",
    "\n",
    "for experiment in experiments:\n",
    "    name = experiment['name']   \n",
    "    print(name)\n",
    "    results = np.zeros((len(seed_range), dim_range.shape[0]))\n",
    "    \n",
    "    for i, seed in enumerate(seed_range):\n",
    "        for j, dim in enumerate(dim_range):\n",
    "            env = SimpleChain(int(dim))\n",
    "            _, num_episodes = train(env,\n",
    "                                   seed=seed,\n",
    "                                   learning_starts_in_steps=(dim+9)*3,\n",
    "                                   max_steps=2000*(dim+9),\n",
    "                                   train_freq_in_steps=10,\n",
    "                                   update_freq_in_steps=60,\n",
    "                                   **common_params, **experiment['params'])\n",
    "            \n",
    "            results[i][j] = num_episodes\n",
    "    np.save(folder+name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def print_results(experiments, folder, to_print=True):\n",
    "    all_stats = []\n",
    "    for i, experiment in enumerate(experiments):\n",
    "        name = experiment['name']\n",
    "        \n",
    "        arr = np.load(folder+name+'.npy')\n",
    "        stats = np.zeros((3, arr.shape[1]))\n",
    "        stats[0] = arr.min(axis=0)\n",
    "        stats[1] = arr.mean(axis=0)\n",
    "        stats[2] = arr.max(axis=0)\n",
    "        all_stats.append(stats)\n",
    "        if to_print:\n",
    "            print(i, name)\n",
    "            print(stats[:,:5])\n",
    "            print('\\n')\n",
    "    return all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 eps_greedy\n",
      "[[ 595.   592.   658.   627.  2000. ]\n",
      " [ 652.  1203.4  980.6 1725.4 2000. ]\n",
      " [ 722.  2000.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "1 ucb-1\n",
      "[[ 109.   118.   132.   244.   211. ]\n",
      " [ 164.2  131.4  205.8 1207.2 1308.8]\n",
      " [ 370.   150.   335.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "2 ucb-2\n",
      "[[ 106.   110.   115.   122.   199. ]\n",
      " [ 107.4  128.   119.6  532.2  983. ]\n",
      " [ 110.   149.   134.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "3 count_based_state_action\n",
      "[[  99.    99.    99.    99.    99. ]\n",
      " [1239.6  860.   859.4  873.6  865.6]\n",
      " [2000.  2000.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "4 count_based_next_state_action\n",
      "[[  99.    99.    99.    99.    99. ]\n",
      " [1239.6  860.   859.4 1619.8 1619.8]\n",
      " [2000.  2000.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "5 count_based_state\n",
      "[[  99.    99.    99.    99.    99. ]\n",
      " [1239.6  860.   859.4  873.6  865.6]\n",
      " [2000.  2000.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "6 count_based_next_state\n",
      "[[  99.    99.    99.    99.    99. ]\n",
      " [1239.6  860.   859.4  874.2  865.6]\n",
      " [2000.  2000.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "7 eps_greedy_count_based_state_action\n",
      "[[ 594.   587.   687.  1668.   838. ]\n",
      " [ 624.8  715.6 1507.2 1930.4 1767.6]\n",
      " [ 725.   846.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "8 eps_greedy_count_based_next_state_action\n",
      "[[ 614.   606.   636.   596.   888. ]\n",
      " [ 649.4  908.4 1228.2 1519.4 1517.4]\n",
      " [ 728.  1647.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "9 eps_greedy_count_based_state\n",
      "[[ 594.   638.   653.   772.  1772. ]\n",
      " [ 640.4 1210.8 1529.2 1754.4 1954.4]\n",
      " [ 717.  2000.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n",
      "10 eps_greedy_count_based_next_state\n",
      "[[ 593.   673.   670.   938.   777. ]\n",
      " [ 654.  1048.6 1607.4 1787.6 1575.8]\n",
      " [ 763.  1974.  2000.  2000.  2000. ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_stats = print_results(experiments, 'results/dqn/chain/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
